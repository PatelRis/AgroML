{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Crops Yield  : A Machine Learning  Approach \n \nThe science of training machines to learn and produce models for future predictions is widely used, and not for nothing.\nAgriculture plays a critical role in the global economy. With the continuing expansion of the human population understanding worldwide crop yield is central to addressing food security challenges and reducing the impacts of climate change. \n\nCrop yield prediction is an important agricultural problem. The Agricultural yield primarily depends on weather conditions (rain, temperature, etc), pesticides and accurate information about history of crop yield is an important thing for making decisions related to agricultural risk management and future predictions.  The basic ingredients that sustain humans are similar. We eat a lot of corn, wheat, rice and other simple crops. In this project the prediction of top 10 most consumed yields all over the world is established by applying machine learning techniques. In this project I will predict crops yield worldwide for 10 most consumed crops. It is a regression problem\n\nCuisine varies greatly around the world, the basic ingredients that sustain humans are pretty similar. We eat a lot of corn, wheat, rice and other simple crops. In this project the prediction of top 10 most consumed yields all over the world is established by applying machine learning techniqus. \n \n These corps include :\n\n- Cassava                \n- Maize                  \n- Plantains and others   \n- Potatoes                \n- Rice, paddy             \n- Sorghum                \n- Soybeans               \n- Sweet potatoes       \n- Wheat                  \n- Yams             \n\n\nIn the project, machine learning methods are applied to predict crop yield using publicly available data from FAO and World Data Bank. \n","metadata":{}},{"cell_type":"markdown","source":"# Part One: Gathering & Cleaning Data\n\n### Crops Yield Data:\n\n\n \nAfter importing required libraries, crops yield of ten most consumed crops around the world was downloaded from FAO webiste.The collected data include country, item, year starting from 1961 to 2016 and yield value. ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.112955Z","iopub.execute_input":"2021-12-07T17:36:03.113241Z","iopub.status.idle":"2021-12-07T17:36:03.118044Z","shell.execute_reply.started":"2021-12-07T17:36:03.113211Z","shell.execute_reply":"2021-12-07T17:36:03.117070Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"df_yield = pd.read_csv('../input/crop-yield-prediction-dataset/yield.csv')\ndf_yield.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.120420Z","iopub.execute_input":"2021-12-07T17:36:03.120710Z","iopub.status.idle":"2021-12-07T17:36:03.224439Z","shell.execute_reply.started":"2021-12-07T17:36:03.120665Z","shell.execute_reply":"2021-12-07T17:36:03.223561Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"df_yield.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.226071Z","iopub.execute_input":"2021-12-07T17:36:03.226352Z","iopub.status.idle":"2021-12-07T17:36:03.241765Z","shell.execute_reply.started":"2021-12-07T17:36:03.226318Z","shell.execute_reply":"2021-12-07T17:36:03.240837Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"df_yield.tail()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.243145Z","iopub.execute_input":"2021-12-07T17:36:03.243446Z","iopub.status.idle":"2021-12-07T17:36:03.262931Z","shell.execute_reply.started":"2021-12-07T17:36:03.243411Z","shell.execute_reply":"2021-12-07T17:36:03.262141Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"Looking at the columns in the csv, we can rename **Value** to **hg/ha_yield** to make it easier to recognise that this is our crops yields production value. In addition to removal of unnecessary coloumns like Area Code, Domain, Item Code, etc.","metadata":{}},{"cell_type":"code","source":"# rename columns.\ndf_yield = df_yield.rename(index=str, columns={\"Value\": \"hg/ha_yield\"})\ndf_yield.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.265060Z","iopub.execute_input":"2021-12-07T17:36:03.265400Z","iopub.status.idle":"2021-12-07T17:36:03.301441Z","shell.execute_reply.started":"2021-12-07T17:36:03.265359Z","shell.execute_reply":"2021-12-07T17:36:03.300659Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# drop unwanted columns.\ndf_yield = df_yield.drop(['Year Code','Element Code','Element','Year Code','Area Code','Domain Code','Domain','Unit','Item Code'], axis=1)\ndf_yield.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.302854Z","iopub.execute_input":"2021-12-07T17:36:03.303150Z","iopub.status.idle":"2021-12-07T17:36:03.316934Z","shell.execute_reply.started":"2021-12-07T17:36:03.303073Z","shell.execute_reply":"2021-12-07T17:36:03.316267Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"df_yield.describe()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.317972Z","iopub.execute_input":"2021-12-07T17:36:03.318652Z","iopub.status.idle":"2021-12-07T17:36:03.341207Z","shell.execute_reply.started":"2021-12-07T17:36:03.318613Z","shell.execute_reply":"2021-12-07T17:36:03.340334Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"From cell above, we know the dataframe starts at 1961 and ends at 2016, this is all the avialable data up to date from FAO. ","metadata":{}},{"cell_type":"code","source":"df_yield.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.342632Z","iopub.execute_input":"2021-12-07T17:36:03.342988Z","iopub.status.idle":"2021-12-07T17:36:03.369804Z","shell.execute_reply.started":"2021-12-07T17:36:03.342949Z","shell.execute_reply":"2021-12-07T17:36:03.369016Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"All of the columns type are in right type. ","metadata":{}},{"cell_type":"markdown","source":"### Climate Data : Rainfall \nThe climatic factors include rainfall and temperature. They are abiotic components, including pesticides and soil, of the environmental factors that influence plant growth and development.\n\n\nRainfall has a dramatic effect on agriculture. For this project rain fall per year information was gathered from World Data Bank. ","metadata":{}},{"cell_type":"code","source":"df_rain = pd.read_csv('../input/crop-yield-prediction-dataset/rainfall.csv')\ndf_rain.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.371235Z","iopub.execute_input":"2021-12-07T17:36:03.371714Z","iopub.status.idle":"2021-12-07T17:36:03.391628Z","shell.execute_reply.started":"2021-12-07T17:36:03.371676Z","shell.execute_reply":"2021-12-07T17:36:03.390879Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"df_rain = df_rain.rename(index=str, columns={\" Area\": 'Area'})","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.393892Z","iopub.execute_input":"2021-12-07T17:36:03.394716Z","iopub.status.idle":"2021-12-07T17:36:03.402777Z","shell.execute_reply.started":"2021-12-07T17:36:03.394671Z","shell.execute_reply":"2021-12-07T17:36:03.401816Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"Making sure that names of columns are unified across all dataframes is important for merging after cleaning afterwards. ","metadata":{}},{"cell_type":"code","source":"# check data types \ndf_rain.info()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.407580Z","iopub.execute_input":"2021-12-07T17:36:03.407796Z","iopub.status.idle":"2021-12-07T17:36:03.424273Z","shell.execute_reply.started":"2021-12-07T17:36:03.407773Z","shell.execute_reply":"2021-12-07T17:36:03.423477Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"We can see from cell above that average_rain_fall_mm_per_year type is an object, we need to turn it to a float value. ","metadata":{}},{"cell_type":"code","source":"# convert average_rain_fall_mm_per_year from object to float\ndf_rain['average_rain_fall_mm_per_year'] = pd.to_numeric(df_rain['average_rain_fall_mm_per_year'],errors = 'coerce')\ndf_rain.info()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.425656Z","iopub.execute_input":"2021-12-07T17:36:03.426134Z","iopub.status.idle":"2021-12-07T17:36:03.445733Z","shell.execute_reply.started":"2021-12-07T17:36:03.426097Z","shell.execute_reply":"2021-12-07T17:36:03.444898Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"Next, droping any empty rows from dataset and merge yield dataframe with rain dataframe by year and area columns","metadata":{}},{"cell_type":"code","source":"df_rain = df_rain.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.447347Z","iopub.execute_input":"2021-12-07T17:36:03.447846Z","iopub.status.idle":"2021-12-07T17:36:03.458916Z","shell.execute_reply.started":"2021-12-07T17:36:03.447806Z","shell.execute_reply":"2021-12-07T17:36:03.458020Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"df_rain.describe()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.460382Z","iopub.execute_input":"2021-12-07T17:36:03.460707Z","iopub.status.idle":"2021-12-07T17:36:03.481054Z","shell.execute_reply.started":"2021-12-07T17:36:03.460672Z","shell.execute_reply":"2021-12-07T17:36:03.479678Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"The rainfall dataframe begins at 1985 and ends at 2016. ","metadata":{}},{"cell_type":"code","source":"# merge yield dataframe with rain dataframe by year and area columns \nyield_df = pd.merge(df_yield, df_rain, on=['Year','Area'])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.482607Z","iopub.execute_input":"2021-12-07T17:36:03.482876Z","iopub.status.idle":"2021-12-07T17:36:03.499879Z","shell.execute_reply.started":"2021-12-07T17:36:03.482845Z","shell.execute_reply":"2021-12-07T17:36:03.499228Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"Now, we view the final shape of the dataframe and info of values:","metadata":{}},{"cell_type":"code","source":"yield_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.501245Z","iopub.execute_input":"2021-12-07T17:36:03.501512Z","iopub.status.idle":"2021-12-07T17:36:03.507332Z","shell.execute_reply.started":"2021-12-07T17:36:03.501479Z","shell.execute_reply":"2021-12-07T17:36:03.506391Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"yield_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.508930Z","iopub.execute_input":"2021-12-07T17:36:03.509209Z","iopub.status.idle":"2021-12-07T17:36:03.525937Z","shell.execute_reply.started":"2021-12-07T17:36:03.509157Z","shell.execute_reply":"2021-12-07T17:36:03.525084Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"We can see that now the years start from the first yield dataframe the starting year was 1961, now it's 1985 because that's when the rainfall data begins. ","metadata":{}},{"cell_type":"code","source":"yield_df.describe()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.527367Z","iopub.execute_input":"2021-12-07T17:36:03.527652Z","iopub.status.idle":"2021-12-07T17:36:03.549977Z","shell.execute_reply.started":"2021-12-07T17:36:03.527617Z","shell.execute_reply":"2021-12-07T17:36:03.549141Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"### Pesticides Data:\nPesticides used for each item and country was also collected from FAO database.  ","metadata":{}},{"cell_type":"code","source":"df_pes = pd.read_csv('../input/crop-yield-prediction-dataset/pesticides.csv')\ndf_pes.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.551228Z","iopub.execute_input":"2021-12-07T17:36:03.551529Z","iopub.status.idle":"2021-12-07T17:36:03.573398Z","shell.execute_reply.started":"2021-12-07T17:36:03.551495Z","shell.execute_reply":"2021-12-07T17:36:03.572551Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"df_pes = df_pes.rename(index=str, columns={\"Value\": \"pesticides_tonnes\"})\ndf_pes = df_pes.drop(['Element','Domain','Unit','Item'], axis=1)\ndf_pes.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.574750Z","iopub.execute_input":"2021-12-07T17:36:03.575075Z","iopub.status.idle":"2021-12-07T17:36:03.589791Z","shell.execute_reply.started":"2021-12-07T17:36:03.575041Z","shell.execute_reply":"2021-12-07T17:36:03.588969Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"df_pes.describe()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.591151Z","iopub.execute_input":"2021-12-07T17:36:03.592126Z","iopub.status.idle":"2021-12-07T17:36:03.610855Z","shell.execute_reply.started":"2021-12-07T17:36:03.592091Z","shell.execute_reply":"2021-12-07T17:36:03.610189Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"df_pes.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.612877Z","iopub.execute_input":"2021-12-07T17:36:03.613275Z","iopub.status.idle":"2021-12-07T17:36:03.627913Z","shell.execute_reply.started":"2021-12-07T17:36:03.613238Z","shell.execute_reply":"2021-12-07T17:36:03.627122Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# merge Pesticides dataframe with yield dataframe \nyield_df = pd.merge(yield_df, df_pes, on=['Year','Area'])\nyield_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.629984Z","iopub.execute_input":"2021-12-07T17:36:03.630479Z","iopub.status.idle":"2021-12-07T17:36:03.644869Z","shell.execute_reply.started":"2021-12-07T17:36:03.630443Z","shell.execute_reply":"2021-12-07T17:36:03.644134Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"yield_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.646035Z","iopub.execute_input":"2021-12-07T17:36:03.646300Z","iopub.status.idle":"2021-12-07T17:36:03.657855Z","shell.execute_reply.started":"2021-12-07T17:36:03.646269Z","shell.execute_reply":"2021-12-07T17:36:03.657069Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"### Average Temprature: \n\nAverage Temprature for each country was colleced from World Bank Data. ","metadata":{}},{"cell_type":"code","source":"avg_temp=  pd.read_csv('../input/crop-yield-prediction-dataset/temp.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.659334Z","iopub.execute_input":"2021-12-07T17:36:03.659806Z","iopub.status.idle":"2021-12-07T17:36:03.695432Z","shell.execute_reply.started":"2021-12-07T17:36:03.659772Z","shell.execute_reply":"2021-12-07T17:36:03.694746Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"avg_temp.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.696691Z","iopub.execute_input":"2021-12-07T17:36:03.696943Z","iopub.status.idle":"2021-12-07T17:36:03.707405Z","shell.execute_reply.started":"2021-12-07T17:36:03.696911Z","shell.execute_reply":"2021-12-07T17:36:03.706542Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"avg_temp.describe()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.708921Z","iopub.execute_input":"2021-12-07T17:36:03.709528Z","iopub.status.idle":"2021-12-07T17:36:03.730367Z","shell.execute_reply.started":"2021-12-07T17:36:03.709492Z","shell.execute_reply":"2021-12-07T17:36:03.729583Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"So average temprature starts from 1743 and ends at 2013, with some empty rows that we have to drop.","metadata":{}},{"cell_type":"code","source":"avg_temp = avg_temp.rename(index=str, columns={\"year\": \"Year\", \"country\":'Area'})\navg_temp.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.735096Z","iopub.execute_input":"2021-12-07T17:36:03.735302Z","iopub.status.idle":"2021-12-07T17:36:03.769791Z","shell.execute_reply.started":"2021-12-07T17:36:03.735280Z","shell.execute_reply":"2021-12-07T17:36:03.769005Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"yield_df = pd.merge(yield_df,avg_temp, on=['Area','Year'])\nyield_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.771090Z","iopub.execute_input":"2021-12-07T17:36:03.771421Z","iopub.status.idle":"2021-12-07T17:36:03.801523Z","shell.execute_reply.started":"2021-12-07T17:36:03.771386Z","shell.execute_reply":"2021-12-07T17:36:03.800690Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"yield_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.802942Z","iopub.execute_input":"2021-12-07T17:36:03.803266Z","iopub.status.idle":"2021-12-07T17:36:03.809778Z","shell.execute_reply.started":"2021-12-07T17:36:03.803232Z","shell.execute_reply":"2021-12-07T17:36:03.808892Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"yield_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.811087Z","iopub.execute_input":"2021-12-07T17:36:03.812088Z","iopub.status.idle":"2021-12-07T17:36:03.839927Z","shell.execute_reply.started":"2021-12-07T17:36:03.812050Z","shell.execute_reply":"2021-12-07T17:36:03.839173Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"yield_df.isnull().sum()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.840900Z","iopub.execute_input":"2021-12-07T17:36:03.841105Z","iopub.status.idle":"2021-12-07T17:36:03.855238Z","shell.execute_reply.started":"2021-12-07T17:36:03.841082Z","shell.execute_reply":"2021-12-07T17:36:03.854490Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"Great, no empty values!","metadata":{}},{"cell_type":"markdown","source":"# Part Two: Data Exploration\n\n","metadata":{}},{"cell_type":"markdown","source":"**yield_df** is the final obtained dataframe; ","metadata":{}},{"cell_type":"code","source":"yield_df.groupby('Item').count()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.856536Z","iopub.execute_input":"2021-12-07T17:36:03.856781Z","iopub.status.idle":"2021-12-07T17:36:03.875389Z","shell.execute_reply.started":"2021-12-07T17:36:03.856750Z","shell.execute_reply":"2021-12-07T17:36:03.874643Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"yield_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.876733Z","iopub.execute_input":"2021-12-07T17:36:03.876981Z","iopub.status.idle":"2021-12-07T17:36:03.903748Z","shell.execute_reply.started":"2021-12-07T17:36:03.876948Z","shell.execute_reply":"2021-12-07T17:36:03.903066Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"It can be noticed the high variance in the values for each columns, later on I'll account for that will scaling. ","metadata":{}},{"cell_type":"code","source":"yield_df['Area'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.905004Z","iopub.execute_input":"2021-12-07T17:36:03.905274Z","iopub.status.idle":"2021-12-07T17:36:03.916973Z","shell.execute_reply.started":"2021-12-07T17:36:03.905243Z","shell.execute_reply":"2021-12-07T17:36:03.916238Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"The dataframe has 101 Countries, ordering these by 10 the highest yield production: ","metadata":{}},{"cell_type":"code","source":"yield_df.groupby(['Area'],sort=True)['hg/ha_yield'].sum().nlargest(10)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.918457Z","iopub.execute_input":"2021-12-07T17:36:03.918700Z","iopub.status.idle":"2021-12-07T17:36:03.931075Z","shell.execute_reply.started":"2021-12-07T17:36:03.918667Z","shell.execute_reply":"2021-12-07T17:36:03.930341Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"India has the highest yield production in the dataset. Inclusing items in the groupby:","metadata":{}},{"cell_type":"code","source":"yield_df.groupby(['Item','Area'],sort=True)['hg/ha_yield'].sum().nlargest(10)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:03.932283Z","iopub.execute_input":"2021-12-07T17:36:03.932532Z","iopub.status.idle":"2021-12-07T17:36:03.950211Z","shell.execute_reply.started":"2021-12-07T17:36:03.932502Z","shell.execute_reply":"2021-12-07T17:36:03.949599Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"India is the highest for production of cassava and potatoes. Potatoes seems to be the dominated crop in the dataset, being the highest in 4 countries. ","metadata":{}},{"cell_type":"markdown","source":"The final dataframe starts from 1990 and ends in 2013, that's 23 years worth of data for 101 countries. ","metadata":{}},{"cell_type":"markdown","source":"Now, exploring the relationships between the colunms of the dataframe, a good way to quickly check correlations among columns is by visualizing the correlation matrix as a heatmap.","metadata":{}},{"cell_type":"code","source":"import sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.951944Z","iopub.execute_input":"2021-12-07T17:36:03.952330Z","iopub.status.idle":"2021-12-07T17:36:03.956389Z","shell.execute_reply.started":"2021-12-07T17:36:03.952299Z","shell.execute_reply":"2021-12-07T17:36:03.955503Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"correlation_data=yield_df.select_dtypes(include=[np.number]).corr()\n\nmask = np.zeros_like(correlation_data, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.palette=\"vlag\"\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(correlation_data, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:03.957692Z","iopub.execute_input":"2021-12-07T17:36:03.957986Z","iopub.status.idle":"2021-12-07T17:36:04.284152Z","shell.execute_reply.started":"2021-12-07T17:36:03.957921Z","shell.execute_reply":"2021-12-07T17:36:04.283475Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"It can be seen from the above correlation map that there is no correlation between any of the colmuns in the dataframe. ","metadata":{}},{"cell_type":"markdown","source":"# Part Three: Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Data Preprocessing is a technique that is used to convert the raw data into a clean data set. In other words, whenever the data is gathered from different sources it is collected in raw format which is not feasible for the analysis.  \n\n\n","metadata":{}},{"cell_type":"code","source":"yield_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:04.285410Z","iopub.execute_input":"2021-12-07T17:36:04.285822Z","iopub.status.idle":"2021-12-07T17:36:04.302287Z","shell.execute_reply.started":"2021-12-07T17:36:04.285787Z","shell.execute_reply":"2021-12-07T17:36:04.301623Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"### Encoding Categorical Variables:\nThere are two categorical columns in the dataframe, categorical data are variables that contain label values rather than numeric values. The number of possible values is often limited to a fixed set, like in this case, items and countries values.\nMany machine learning algorithms cannot operate on label data directly. They require all input variables and output variables to be numeric.\n\nThis means that categorical data must be converted to a numerical form. One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction. For that purpose, One-Hot Encoding will be used to convert these two columns to one-hot numeric array.\n\nThe categorical value represents the numerical value of the entry in the dataset. This encoding will create a binary column for each category and returns a matrix with the results. \n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.303904Z","iopub.execute_input":"2021-12-07T17:36:04.304590Z","iopub.status.idle":"2021-12-07T17:36:04.308250Z","shell.execute_reply.started":"2021-12-07T17:36:04.304556Z","shell.execute_reply":"2021-12-07T17:36:04.307481Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"yield_df_onehot = pd.get_dummies(yield_df, columns=['Area',\"Item\"], prefix = ['Country',\"Item\"])\nfeatures=yield_df_onehot.loc[:, yield_df_onehot.columns != 'hg/ha_yield']\nlabel=yield_df['hg/ha_yield']\nfeatures.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.309317Z","iopub.execute_input":"2021-12-07T17:36:04.309799Z","iopub.status.idle":"2021-12-07T17:36:04.357478Z","shell.execute_reply.started":"2021-12-07T17:36:04.309760Z","shell.execute_reply":"2021-12-07T17:36:04.356705Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"features = features.drop(['Year'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.358705Z","iopub.execute_input":"2021-12-07T17:36:04.359016Z","iopub.status.idle":"2021-12-07T17:36:04.366968Z","shell.execute_reply.started":"2021-12-07T17:36:04.358982Z","shell.execute_reply":"2021-12-07T17:36:04.366080Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"features.info()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:04.368675Z","iopub.execute_input":"2021-12-07T17:36:04.369288Z","iopub.status.idle":"2021-12-07T17:36:04.386511Z","shell.execute_reply.started":"2021-12-07T17:36:04.369249Z","shell.execute_reply":"2021-12-07T17:36:04.385865Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:04.387597Z","iopub.execute_input":"2021-12-07T17:36:04.388219Z","iopub.status.idle":"2021-12-07T17:36:04.410775Z","shell.execute_reply.started":"2021-12-07T17:36:04.388184Z","shell.execute_reply":"2021-12-07T17:36:04.410100Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"\n### Scaling Features: \n\nTaking a look at the dataset above, it contains features highly varying in magnitudes, units and range. The features with high magnitudes will weigh in a lot more in the distance calculations than features with low magnitudes.\n\nTo supress this effect, we need to bring all features to the same level of magnitudes. This can be acheived by scaling.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nfeatures=scaler.fit_transform(features) ","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.411874Z","iopub.execute_input":"2021-12-07T17:36:04.412100Z","iopub.status.idle":"2021-12-07T17:36:04.454389Z","shell.execute_reply.started":"2021-12-07T17:36:04.412071Z","shell.execute_reply":"2021-12-07T17:36:04.453628Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"After dropping year column in addition to scaling all values in features, the resulting array will look something like this : ","metadata":{}},{"cell_type":"code","source":"features","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.455767Z","iopub.execute_input":"2021-12-07T17:36:04.456043Z","iopub.status.idle":"2021-12-07T17:36:04.462047Z","shell.execute_reply.started":"2021-12-07T17:36:04.456011Z","shell.execute_reply":"2021-12-07T17:36:04.461261Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"## Training Data: \n\nThe dataset will be split to two datasets, the training dataset and test dataset. The data is usually tend to be split inequality because training the model usually requires as much data-points as possible.The common splits are 70/30 or 80/20 for train/test.\n\nThe training dataset is the intial dataset used to train ML algorithm to learn and produce right predictions. (70% of dataset is training dataset)\n\nThe test dataset, however, is used to assess how well ML algorithm is trained with the training dataset. You can’t simply reuse the training dataset in the testing stage because ML algorithm will already “know” the expected output, which defeats the purpose of testing the algorithm. (30% of dataset is testing dataset) \n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data, test_data, train_labels, test_labels = train_test_split(features, label, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.463476Z","iopub.execute_input":"2021-12-07T17:36:04.463966Z","iopub.status.idle":"2021-12-07T17:36:04.495999Z","shell.execute_reply.started":"2021-12-07T17:36:04.463930Z","shell.execute_reply":"2021-12-07T17:36:04.495253Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"#write final df to csv file \n#yield_df.to_csv('../input/crop-yield-prediction-dataset/yield_df.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.497335Z","iopub.execute_input":"2021-12-07T17:36:04.497611Z","iopub.status.idle":"2021-12-07T17:36:04.501126Z","shell.execute_reply.started":"2021-12-07T17:36:04.497578Z","shell.execute_reply":"2021-12-07T17:36:04.500350Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data, test_data, train_labels, test_labels = train_test_split(features, label, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.502524Z","iopub.execute_input":"2021-12-07T17:36:04.503015Z","iopub.status.idle":"2021-12-07T17:36:04.534656Z","shell.execute_reply.started":"2021-12-07T17:36:04.502978Z","shell.execute_reply":"2021-12-07T17:36:04.533887Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":"# Part Four: Model Comparison & Selection \n\nBefore deciding on an algorithem to use, first we need to evaluate, compare and choose the best one that fits this specific dataset.\n\nUsually, when working on a machine learning problem with a given dataset, we try different models and techniques to solve an optimization problem and fit the most accurate model, that will neither overfit nor underfit the model. \n \nFor this project, we'll compare between the following models : \n\n- Gradient Boosting Regressor\n- Random Forest Regressor\n- SVM \n- Decision Tree Regressor\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ndef compare_models(model):\n    model_name = model.__class__.__name__\n    fit=model.fit(train_data,train_labels)\n    y_pred=fit.predict(test_data)\n    r2=r2_score(test_labels,y_pred)\n    return([model_name,r2])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.537204Z","iopub.execute_input":"2021-12-07T17:36:04.537663Z","iopub.status.idle":"2021-12-07T17:36:04.543171Z","shell.execute_reply.started":"2021-12-07T17:36:04.537627Z","shell.execute_reply":"2021-12-07T17:36:04.542187Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodels = [\n    GradientBoostingRegressor(n_estimators=200, max_depth=3, random_state=0),\n     RandomForestRegressor(n_estimators=200, max_depth=3, random_state=0),\n    svm.SVR(),\n   DecisionTreeRegressor()\n]","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:36:04.544547Z","iopub.execute_input":"2021-12-07T17:36:04.544945Z","iopub.status.idle":"2021-12-07T17:36:04.553618Z","shell.execute_reply.started":"2021-12-07T17:36:04.544908Z","shell.execute_reply":"2021-12-07T17:36:04.552869Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"model_train=list(map(compare_models,models)) ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:36:04.555134Z","iopub.execute_input":"2021-12-07T17:36:04.555475Z","iopub.status.idle":"2021-12-07T17:38:12.818676Z","shell.execute_reply.started":"2021-12-07T17:36:04.555441Z","shell.execute_reply":"2021-12-07T17:38:12.817896Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"print(*model_train, sep = \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:12.819899Z","iopub.execute_input":"2021-12-07T17:38:12.820504Z","iopub.status.idle":"2021-12-07T17:38:12.826102Z","shell.execute_reply.started":"2021-12-07T17:38:12.820468Z","shell.execute_reply":"2021-12-07T17:38:12.825129Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"The evaluation metric is set based on **R^2 (coefficient of determination)** regression score function, that will represents the proportion of the variance for items (crops) in the regression model. **R^2** score shows how well terms (data points) fit a curve or line.\n\n**R^2** is a statistical measure between 0 and 1 which calculates how similar a regression line is to the data it’s fitted to. If it’s a 1, the model 100% predicts the data variance; if it’s a 0, the model predicts none of the variance. \n\nFrom results viewd above, **Decision Tree Regressor** has the highest R^2 score 0f **96%**, **GradientBoostingRegressor** comes second. \n\n\n I'll also calculate **Adjusted R^2** also indicates how well terms fit a curve or line, but adjusts for the number of terms in a model. If you add more and more useless variables to a model, adjusted r-squared will decrease. If you add more useful variables, adjusted r-squared will increase.\nAdjusted R2 will always be less than or equal to R2. ","metadata":{}},{"cell_type":"code","source":"yield_df_onehot = yield_df_onehot.drop(['Year'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:12.827525Z","iopub.execute_input":"2021-12-07T17:38:12.827965Z","iopub.status.idle":"2021-12-07T17:38:12.839899Z","shell.execute_reply.started":"2021-12-07T17:38:12.827929Z","shell.execute_reply":"2021-12-07T17:38:12.839242Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"yield_df_onehot.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:12.841260Z","iopub.execute_input":"2021-12-07T17:38:12.841522Z","iopub.status.idle":"2021-12-07T17:38:12.864152Z","shell.execute_reply.started":"2021-12-07T17:38:12.841490Z","shell.execute_reply":"2021-12-07T17:38:12.863154Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"#setting test data to columns from dataframe and excluding 'hg/ha_yield' values where ML model should be predicting \n\ntest_df=pd.DataFrame(test_data,columns=yield_df_onehot.loc[:, yield_df_onehot.columns != 'hg/ha_yield'].columns) \n\n# using stack function to return a reshaped DataFrame by pivoting the columns of the current dataframe\n\ncntry=test_df[[col for col in test_df.columns if 'Country' in col]].stack()[test_df[[col for col in test_df.columns if 'Country' in col]].stack()>0]\ncntrylist=list(pd.DataFrame(cntry).index.get_level_values(1))\ncountries=[i.split(\"_\")[1] for i in cntrylist]\nitm=test_df[[col for col in test_df.columns if 'Item' in col]].stack()[test_df[[col for col in test_df.columns if 'Item' in col]].stack()>0]\nitmlist=list(pd.DataFrame(itm).index.get_level_values(1))\nitems=[i.split(\"_\")[1] for i in itmlist]","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:12.865482Z","iopub.execute_input":"2021-12-07T17:38:12.866029Z","iopub.status.idle":"2021-12-07T17:38:13.021776Z","shell.execute_reply.started":"2021-12-07T17:38:12.865983Z","shell.execute_reply":"2021-12-07T17:38:13.020965Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:13.023212Z","iopub.execute_input":"2021-12-07T17:38:13.023465Z","iopub.status.idle":"2021-12-07T17:38:13.056131Z","shell.execute_reply.started":"2021-12-07T17:38:13.023433Z","shell.execute_reply":"2021-12-07T17:38:13.055267Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"test_df.drop([col for col in test_df.columns if 'Item' in col],axis=1,inplace=True)\ntest_df.drop([col for col in test_df.columns if 'Country' in col],axis=1,inplace=True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:13.057639Z","iopub.execute_input":"2021-12-07T17:38:13.057909Z","iopub.status.idle":"2021-12-07T17:38:13.073974Z","shell.execute_reply.started":"2021-12-07T17:38:13.057876Z","shell.execute_reply":"2021-12-07T17:38:13.073111Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"test_df['Country']=countries\ntest_df['Item']=items\ntest_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:38:13.076399Z","iopub.execute_input":"2021-12-07T17:38:13.076695Z","iopub.status.idle":"2021-12-07T17:38:13.093683Z","shell.execute_reply.started":"2021-12-07T17:38:13.076651Z","shell.execute_reply":"2021-12-07T17:38:13.092988Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"clf=DecisionTreeRegressor()\nmodel=clf.fit(train_data,train_labels)\n\ntest_df[\"yield_predicted\"]= model.predict(test_data)\ntest_df[\"yield_actual\"]=pd.DataFrame(test_labels)[\"hg/ha_yield\"].tolist()\ntest_group=test_df.groupby(\"Item\")\ntest_group.apply(lambda x: r2_score(x.yield_actual,x.yield_predicted))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:38:13.095028Z","iopub.execute_input":"2021-12-07T17:38:13.096496Z","iopub.status.idle":"2021-12-07T17:38:13.295612Z","shell.execute_reply.started":"2021-12-07T17:38:13.096463Z","shell.execute_reply":"2021-12-07T17:38:13.294939Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"# So let's run the model actual values against the predicted ones \n\nfig, ax = plt.subplots() \n\nax.scatter(test_df[\"yield_actual\"], test_df[\"yield_predicted\"],edgecolors=(0, 0, 0))\n\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nax.set_title(\"Actual vs Predicted\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:13.296991Z","iopub.execute_input":"2021-12-07T17:38:13.297254Z","iopub.status.idle":"2021-12-07T17:38:13.512186Z","shell.execute_reply.started":"2021-12-07T17:38:13.297222Z","shell.execute_reply":"2021-12-07T17:38:13.511548Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"markdown","source":"The figure above shows the goodness of the fit with the predictions visualized as a line. It can be seen that R Square score is excellent. This means that we have found a good fitting model to predict the crops yield value for a certain country. Adding more features, like climate data; wind and pollution, the economical situation of a given country and so on will probably enhance the model’s predictions. \n","metadata":{}},{"cell_type":"code","source":"def adjusted_r_squared(y,yhat,x):\n    score=1- (((1-(r2_score(y,yhat)))*(len(y)-1))/(len(y)-x.shape[1]-2))\n    return score\n\ntest_group.apply(lambda x: adjusted_r_squared(x.yield_actual,x.yield_predicted,x))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-07T17:38:13.513370Z","iopub.execute_input":"2021-12-07T17:38:13.513741Z","iopub.status.idle":"2021-12-07T17:38:13.531794Z","shell.execute_reply.started":"2021-12-07T17:38:13.513706Z","shell.execute_reply":"2021-12-07T17:38:13.531000Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"# Part Five: Model Results & Conclusions\n\n","metadata":{}},{"cell_type":"code","source":"varimp= {'imp':model.feature_importances_,'names':yield_df_onehot.columns[yield_df_onehot.columns!=\"hg/ha_yield\"]}","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:13.533098Z","iopub.execute_input":"2021-12-07T17:38:13.533749Z","iopub.status.idle":"2021-12-07T17:38:13.538256Z","shell.execute_reply.started":"2021-12-07T17:38:13.533713Z","shell.execute_reply":"2021-12-07T17:38:13.537524Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"a4_dims = (8.27,16.7)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndf=pd.DataFrame.from_dict(varimp)\ndf.sort_values(ascending=False,by=[\"imp\"],inplace=True)\ndf=df.dropna()\nsns.barplot(x=\"imp\",y=\"names\",palette=\"vlag\",data=df,orient=\"h\",ax=ax);","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:13.539506Z","iopub.execute_input":"2021-12-07T17:38:13.539953Z","iopub.status.idle":"2021-12-07T17:38:16.443197Z","shell.execute_reply.started":"2021-12-07T17:38:13.539916Z","shell.execute_reply":"2021-12-07T17:38:16.442497Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"markdown","source":"Getting only top 7 of features importance in the model:","metadata":{}},{"cell_type":"code","source":"#7 most important factors that affect crops \na4_dims = (16.7, 8.27)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndf=pd.DataFrame.from_dict(varimp)\ndf.sort_values(ascending=False,by=[\"imp\"],inplace=True)\ndf=df.dropna()\ndf=df.nlargest(7, 'imp')\nsns.barplot(x=\"imp\",y=\"names\",palette=\"vlag\",data=df,orient=\"h\",ax=ax);","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:16.444150Z","iopub.execute_input":"2021-12-07T17:38:16.444404Z","iopub.status.idle":"2021-12-07T17:38:16.702729Z","shell.execute_reply.started":"2021-12-07T17:38:16.444371Z","shell.execute_reply":"2021-12-07T17:38:16.702060Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"markdown","source":"The crop being potatoes has the highest importance in the decision making for the model, where it's the highest crops in the dataset. Cassava too, then as expected we see the effect of pesticides, where its the third most important feature, and then if the crop is sweet potatoes, we see some of the highest crops in features importance in dataset. \n\nIf the crop is grown in India, makes sense since Indis has the largest crops sum in the dataset. Then comes rainfall and temprature. Thr first assumption about these features were correct, where they all significanally impact the expected crops yield in the model. ","metadata":{}},{"cell_type":"code","source":"#Boxplot that shows yield for each item \na4_dims = (16.7, 8.27)\n\nfig, ax = plt.subplots(figsize=a4_dims)\nsns.boxplot(x=\"Item\",y=\"hg/ha_yield\",palette=\"vlag\",data=yield_df,ax=ax);","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:38:16.703953Z","iopub.execute_input":"2021-12-07T17:38:16.704383Z","iopub.status.idle":"2021-12-07T17:38:17.231767Z","shell.execute_reply.started":"2021-12-07T17:38:16.704348Z","shell.execute_reply":"2021-12-07T17:38:17.231024Z"},"trusted":true},"execution_count":138,"outputs":[]}]}